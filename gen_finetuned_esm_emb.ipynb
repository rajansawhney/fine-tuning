{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to generate embeddings using ESM2-3B finetuned with siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import esm\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.nn import CosineSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [\n",
    "    (\"YP_009794187.1\", \"MDLSAIGFASKQFRVIPVEKGNLVTDFIQGKFQVIGVECNTRGAYGSPIQQSLSRRFPEM\"),\n",
    "    (\"YP_009293175.1\", \"MLIFRDERHVEGDLFNAPETYKVITINCVGAMGKGIALACRERYPDLYENYRTRCRAGEI\"),\n",
    "    (\"YP_009882144.1\", \"MIKQYVNYDLLDAFEHNDFDAIVHGCNCFHTMGAGIAGAIAKRFPVAVEADKKTEYGDWS\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, alphabet = esm.pretrained.esm2_t36_3B_UR50D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('YP_009794187.1',\n",
       " 'MDLSAIGFASKQFRVIPVEKGNLVTDFIQGKFQVIGVECNTRGAYGSPIQQSLSRRFPEM')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_id1, seq_str1, tokenized_input1 = tokenizer([seqs[0]])\n",
    "seq_id2, seq_str2, tokenized_input2 = tokenizer([seqs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 20, 13,  4,  8,  5, 12,  6, 18,  5,  8, 15, 16, 18, 10,  7, 12, 14,\n",
       "          7,  9, 15,  6, 17,  4,  7, 11, 13, 18, 12, 16,  6, 15, 18, 16,  7, 12,\n",
       "          6,  7,  9, 23, 17, 11, 10,  6,  5, 19,  6,  8, 14, 12, 16, 16,  8,  4,\n",
       "          8, 10, 10, 18, 14,  9, 20,  2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_checkpoint = '3b_model_checkpoint.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(layers):\n",
    "    new_state_dict = {}\n",
    "    for name, param in layers.items():\n",
    "        new_name = \".\".join(name.split(\".\")[1:])\n",
    "        new_state_dict[new_name] = param\n",
    "\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = remap(torch.load(finetuned_checkpoint))\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embedding1 = model(tokenized_input1, repr_layers=[model.num_layers])[\"representations\"][model.num_layers] # embedding is of shape: [1, seq_len+2, 2560]\n",
    "    embedding2 = embedding1[0][1:-1] # to remove padding; resulting shape: [seqlen, 2560]\n",
    "\n",
    "    embedding1 = model(tokenized_input2, repr_layers=[model.num_layers])[\"representations\"][model.num_layers] # embedding is of shape: [1, seq_len+2, 2560]\n",
    "    embedding2 = embedding2[0][1:-1]\n",
    "    torch.save(embedding1, f\"tmp/{seq_id1[0]}.pt\")\n",
    "    torch.save(embedding2, f\"tmp/{seq_id2[0]}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the FASTA file and the output path\n",
    "fasta_file_path = \"data/sample.fasta\"\n",
    "output_path = \"tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences =  3\n",
      "Seq ids:\n",
      "['YP_009794187.1', 'YP_009293175.1', 'YP_009882144.1']\n"
     ]
    }
   ],
   "source": [
    "# Read sequences from the FASTA file and process them\n",
    "records = list(SeqIO.parse(fasta_file_path, \"fasta\"))\n",
    "num_records = len(records)  # number of sequences\n",
    "print('Number of sequences = ', num_records)\n",
    "print('Seq ids:')\n",
    "print([record.id for record in records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(layers):\n",
    "    new_state_dict = {}\n",
    "    for name, param in layers.items():\n",
    "        new_name = \".\".join(name.split(\".\")[1:])\n",
    "        new_state_dict[new_name] = param\n",
    "    return new_state_dict\n",
    "\n",
    "def get_model_and_tokenizer(weight_path, device='cpu', model_type=esm.pretrained.esm2_t36_3B_UR50D):\n",
    "    model, alphabet = model_type()\n",
    "    tokenizer = alphabet.get_batch_converter()\n",
    "    state_dict = remap(torch.load(weight_path, map_location=device))\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model, tokenizer\n",
    "\n",
    "def run_model(model, tokenizer, sequence, layers=None, device='cpu'):\n",
    "    if layers==None:\n",
    "        layers = [model.num_layers] # last layer\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # pdb.set_trace()\n",
    "        try:\n",
    "            _, _, tokenized_inputs = tokenizer([sequence])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            raise e\n",
    "        tokenized_inputs = tokenized_inputs.to(device)\n",
    "        model = model.to(device)\n",
    "        output = {}\n",
    "        output[\"mean_representations\"] = {}\n",
    "        output[\"representations\"] = model(tokenized_inputs, repr_layers=layers)[\"representations\"]\n",
    "        # remove padding bos, eos\n",
    "        for layer in layers:\n",
    "            output[\"representations\"][layer] = output[\"representations\"][layer][:,1:-1,:] \n",
    "            output[\"mean_representations\"][layer] = torch.mean(output[\"representations\"][layer], dim=1)[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "print('Loading model...')\n",
    "model, tokenizer = get_model_and_tokenizer('../PooledAAEmbeddings/3b_model_checkpoint.pt', device='cpu')\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 100%|██████████| 3/3 [01:44<00:00, 34.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Embeddings saved at: tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "layers = [36]\n",
    "# Process each sequence and save the embeddings\n",
    "for record in tqdm(records, total=num_records, desc=\"Processing sequences\"):\n",
    "    seq_id = record.id\n",
    "    sequence = str(record.seq)\n",
    "    # NOTE: embeddings have a start and end padding token\n",
    "    embedding = run_model(model, tokenizer, (seq_id, sequence), device='cpu')\n",
    "    assert(len(sequence) == embedding[\"representations\"][layers[0]].size()[1])\n",
    "    # Save the embedding\n",
    "    torch.save(embedding, f\"{output_path}/{seq_id}.pt\")\n",
    "\n",
    "print('Done. Embeddings saved at:', output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_id1 = 'YP_009794187.1'\n",
    "seq_id2 = 'YP_009293175.1'\n",
    "seq_id3 = 'YP_009882144.1'\n",
    "\n",
    "emb1 = torch.load(f'tmp/{seq_id1}.pt')\n",
    "emb2 = torch.load(f'tmp/{seq_id2}.pt')\n",
    "emb3 = torch.load(f'tmp/{seq_id3}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1_mean = emb1[\"mean_representations\"][36]\n",
    "emb2_mean = emb2[\"mean_representations\"][36]\n",
    "emb3_mean = emb3[\"mean_representations\"][36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cosine Similarity\n",
    "##### using: https://pytorch.org/docs/stable/generated/torch.nn.CosineSimilarity.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = CosineSimilarity(dim=0, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9778)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(emb1_mean, emb2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9779)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(emb1_mean, emb3_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9798)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(emb2_mean, emb3_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
